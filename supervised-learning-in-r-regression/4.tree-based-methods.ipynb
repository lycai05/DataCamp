{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the right number of trees for a gradient boosting machine\n",
    "In this exercise you will get ready to build a gradient boosting model to predict the number of bikes rented in an hour as a function of the weather and the type and time of day. You will train the model on data from the month of July.\n",
    "\n",
    "The July data is loaded into your workspace. Remember that bikesJuly.treat no longer has the outcome column, so you must get it from the untreated data: bikesJuly$cnt.\n",
    "\n",
    "You will use the xgboost package to fit the random forest model. The function xgb.cv() uses cross-validation to estimate the out-of-sample learning error as each new tree is added to the model. The appropriate number of trees to use in the final model is the number that minimizes the holdout RMSE.\n",
    "\n",
    "For this exercise, the key arguments to the xgb.cv() call are:\n",
    "\n",
    "- data: a numeric matrix.\n",
    "- label: vector of outcomes (also numeric).\n",
    "- nrounds: the maximum number of rounds (trees to build).\n",
    "- nfold: the number of folds for the cross-validation. 5 is a good number.\n",
    "- objective: \"reg:linear\" for continuous outcomes.\n",
    "- eta: the learning rate.\n",
    "- max_depth: depth of trees.\n",
    "- early_stopping_rounds: after this many rounds without improvement, stop.\n",
    "- verbose: 0 to stay silent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit an xgboost bike rental model and predict\n",
    "In this exercise you will fit a gradient boosting model using xgboost() to predict the number of bikes rented in an hour as a function of the weather and the type and time of day. You will train the model on data from the month of July and predict on data for the month of August.\n",
    "\n",
    "The datasets for July and August are loaded into your workspace. Remember the vtreat-ed data no longer has the outcome column, so you must get it from the original data (the cnt column).\n",
    "\n",
    "For convenience, the number of trees to use, ntrees from the previous exercise is in the workspace.\n",
    "\n",
    "The arguments to xgboost() are similar to those of xgb.cv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the workspace\n",
    "ls()\n",
    "\n",
    "# The number of trees to use, as determined by xgb.cv\n",
    "ntrees\n",
    "\n",
    "# Run xgboost\n",
    "bike_model_xgb <- xgboost(data = as.matrix(bikesJuly.treat), # training data as matrix\n",
    "                   label = bikesJuly$cnt,  # column of outcomes\n",
    "                   nrounds = ntrees,       # number of trees to build\n",
    "                   objective = \"reg:linear\", # objective\n",
    "                   eta = 0.3,\n",
    "                   depth = 6,\n",
    "                   verbose = 0  # silent\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "bikesAugust$pred <- predict(bike_model_xgb, as.matrix(bikesAugust.treat))\n",
    "\n",
    "# Plot predictions (on x axis) vs actual bike rental count\n",
    "ggplot(bikesAugust, aes(x = pred, y = cnt)) + \n",
    "  geom_point() + \n",
    "  geom_abline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fit_an_xgboost_bike_rental_model_and_predict](./figures/fit_an_xgboost_bike_rental_model_and_predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the xgboost bike rental model\n",
    "In this exercise you will evaluate the gradient boosting model bike_model_xgb that you fit in the last exercise, using data from the month of August. You'll compare this model's RMSE for August to the RMSE of previous models that you've built.\n",
    "\n",
    "The dataset bikesAugust is in the workspace. You have already made predictions using the xgboost model; they are in the column pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikesAugust is in the workspace\n",
    "str(bikesAugust)\n",
    "\n",
    "# Calculate RMSE\n",
    "bikesAugust %>%\n",
    "  mutate(residuals = cnt - pred) %>%\n",
    "  summarize(rmse = sqrt(mean(residuals^2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this gradient boosting made some negative predictions, overall it makes smaller errors than the previous two models. Perhaps rounding negative predictions up to zero is a reasonable tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the xgboost bike rental model\n",
    "You've now seen three different ways to model the bike rental data. For this example, you've seen that the gradient boosting model had the smallest RMSE. To finish up the course, let's compare the gradient boosting model's predictions to the other two models as a function of time.\n",
    "\n",
    "On completing this exercise, you will have completed the course. Congratulations! Now you have the tools to apply a variety of approaches to your regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print quasipoisson_plot\n",
    "print(quasipoisson_plot)\n",
    "\n",
    "# Print randomforest_plot\n",
    "print(randomforest_plot)\n",
    "\n",
    "# Plot predictions and actual bike rentals as a function of time (days)\n",
    "bikesAugust %>% \n",
    "  mutate(instant = (instant - min(instant))/24) %>%  # set start to 0, convert unit to days\n",
    "  gather(key = valuetype, value = value, cnt, pred) %>%\n",
    "  filter(instant < 14) %>% # first two weeks\n",
    "  ggplot(aes(x = instant, y = value, color = valuetype, linetype = valuetype)) + \n",
    "  geom_point() + \n",
    "  geom_line() + \n",
    "  scale_x_continuous(\"Day\", breaks = 0:14, labels = 0:14) + \n",
    "  scale_color_brewer(palette = \"Dark2\") + \n",
    "  ggtitle(\"Predicted August bike rentals, Gradient Boosting model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting pattern captures rental variations due to time of day and other factors better than the previous models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualize_the_xgboost_bike_rental_model_1](./figures/visualize_the_xgboost_bike_rental_model_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualize_the_xgboost_bike_rental_model_3](./figures/visualize_the_xgboost_bike_rental_model_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualize_the_xgboost_bike_rental_model_2](./figures/visualize_the_xgboost_bike_rental_model_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterlab]",
   "language": "python",
   "name": "conda-env-jupyterlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
