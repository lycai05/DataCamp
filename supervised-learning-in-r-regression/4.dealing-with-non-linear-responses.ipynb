{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a model of sparrow survival probability\n",
    "In this exercise, you will estimate the probability that a sparrow survives a severe winter storm, based on physical characteristics of the sparrow. The dataset sparrow is loaded into your workspace. The outcome to be predicted is status (\"Survived\", \"Perished\"). The variables we will consider are:\n",
    "\n",
    "- total_length: length of the bird from tip of beak to tip of tail (mm)\n",
    "- weight: in grams\n",
    "- humerus : length of humerus (\"upper arm bone\" that connects the wing to the body) (inches)\n",
    "\n",
    "Remember that when using glm() to create a logistic regression model, you must explicitly specify that family = binomial:\n",
    "\n",
    "```\n",
    "glm(formula, data = data, family = binomial)\n",
    "```\n",
    "You will call summary(), broom::glance() to see different functions for examining a logistic regression model. One of the diagnostics that you will look at is the analog to R^2, called pseudo-R^2.\n",
    "\n",
    "pseudoR^2=1âˆ’deviance/null.deviance\n",
    "You can think of deviance as analogous to variance: it is a measure of the variation in categorical data. The pseudo-R^2 is analogous to R^2 for standard regression: R2 is a measure of the \"variance explained\" of a regression model. The pseudo-R2 is a measure of the \"deviance explained\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparrow is in the workspace\n",
    "summary(sparrow)\n",
    "#       status       age             total_length      wingspan    \n",
    "# Perished:36   Length:87          Min.   :153.0   Min.   :236.0  \n",
    "# Survived:51   Class :character   1st Qu.:158.0   1st Qu.:245.0  \n",
    "#               Mode  :character   Median :160.0   Median :247.0  \n",
    "#                                   Mean   :160.4   Mean   :247.5  \n",
    "#                                   3rd Qu.:162.5   3rd Qu.:251.0  \n",
    "#                                   Max.   :167.0   Max.   :256.0  \n",
    "#     weight       beak_head        humerus           femur       \n",
    "# Min.   :23.2   Min.   :29.80   Min.   :0.6600   Min.   :0.6500  \n",
    "# 1st Qu.:24.7   1st Qu.:31.40   1st Qu.:0.7250   1st Qu.:0.7000  \n",
    "# Median :25.8   Median :31.70   Median :0.7400   Median :0.7100  \n",
    "# Mean   :25.8   Mean   :31.64   Mean   :0.7353   Mean   :0.7134  \n",
    "# 3rd Qu.:26.7   3rd Qu.:32.10   3rd Qu.:0.7500   3rd Qu.:0.7300  \n",
    "# Max.   :31.0   Max.   :33.00   Max.   :0.7800   Max.   :0.7600  \n",
    "#     legbone          skull           sternum      \n",
    "# Min.   :1.010   Min.   :0.5600   Min.   :0.7700  \n",
    "# 1st Qu.:1.110   1st Qu.:0.5900   1st Qu.:0.8300  \n",
    "# Median :1.130   Median :0.6000   Median :0.8500  \n",
    "# Mean   :1.131   Mean   :0.6032   Mean   :0.8511  \n",
    "# 3rd Qu.:1.160   3rd Qu.:0.6100   3rd Qu.:0.8800  \n",
    "# Max.   :1.230   Max.   :0.6400   Max.   :0.9300\n",
    " \n",
    "# Create the survived column\n",
    "sparrow$survived <- sparrow$status == \"Survived\"\n",
    "\n",
    "# Create the formula\n",
    "(fmla <- survived ~ total_length + weight + humerus)\n",
    "# survived ~ total_length + weight + humerus\n",
    "\n",
    "# Fit the logistic regression model\n",
    "sparrow_model <- glm(fmla, data = sparrow, family = \"binomial\")\n",
    "\n",
    "\n",
    "# Call summary\n",
    "summary(sparrow_model)\n",
    "# Call:\n",
    "# glm(formula = fmla, family = \"binomial\", data = sparrow)\n",
    "\n",
    "# Deviance Residuals: \n",
    "#     Min       1Q   Median       3Q      Max  \n",
    "# -2.1117  -0.6026   0.2871   0.6577   1.7082  \n",
    "\n",
    "# Coefficients:\n",
    "#             Estimate Std. Error z value Pr(>|z|)    \n",
    "# (Intercept)   46.8813    16.9631   2.764 0.005715 ** \n",
    "# total_length  -0.5435     0.1409  -3.858 0.000115 ***\n",
    "# weight        -0.5689     0.2771  -2.053 0.040060 *  \n",
    "# humerus       75.4610    19.1586   3.939 8.19e-05 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# (Dispersion parameter for binomial family taken to be 1)\n",
    "\n",
    "#     Null deviance: 118.008  on 86  degrees of freedom\n",
    "# Residual deviance:  75.094  on 83  degrees of freedom\n",
    "# AIC: 83.094\n",
    "\n",
    "# Number of Fisher Scoring iterations: 5\n",
    "\n",
    "# Call glance\n",
    "(perf <- glance(sparrow_model))\n",
    "#   null.deviance df.null    logLik      AIC      BIC deviance df.residual\n",
    "# 1      118.0084      86 -37.54718 83.09436 92.95799 75.09436          83\n",
    "\n",
    "# Calculate pseudo-R-squared\n",
    "(pseudoR2 <- 1- perf$deviance / perf$null.deviance)\n",
    "# [1] 0.3636526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict sparrow survival\n",
    "In this exercise you will predict the probability of survival using the sparrow survival model from the previous exercise.\n",
    "\n",
    "Recall that when calling predict() to get the predicted probabilities from a glm() model, you must specify that you want the response:\n",
    "```\n",
    "predict(model, type = \"response\")\n",
    "```\n",
    "Otherwise, predict() on a logistic regression model returns the predicted log-odds of the event, not the probability.\n",
    "\n",
    "You will also use the GainCurvePlot() function to plot the gain curve from the model predictions. If the model's gain curve is close to the ideal (\"wizard\") gain curve, then the model sorted the sparrows well: that is, the model predicted that sparrows that actually survived would have a higher probability of survival. The inputs to the GainCurvePlot() function are:\n",
    "\n",
    "- frame: data frame with prediction column and ground truth column\n",
    "- xvar: the name of the column of predictions (as a string)\n",
    "- truthVar: the name of the column with actual outcome (as a string)\n",
    "- title: a title for the plot (as a string)\n",
    "\n",
    "```\n",
    "GainCurvePlot(frame, xvar, truthVar, title)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "sparrow$pred <- predict(sparrow_model, type = \"response\")\n",
    "\n",
    "# Look at gain curve\n",
    "GainCurvePlot(sparrow, \"pred\", \"survived\", \"sparrow survival model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict_sparrow_survival](./figures/predict_sparrow_survival.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a model to predict bike rental counts\n",
    "In this exercise you will build a model to predict the number of bikes rented in an hour as a function of the weather, the type of day (holiday, working day, or weekend), and the time of day. You will train the model on data from the month of July.\n",
    "\n",
    "The data frame has the columns:\n",
    "\n",
    "- cnt: the number of bikes rented in that hour (the outcome)\n",
    "- hr: the hour of the day (0-23, as a factor)\n",
    "- holiday: TRUE/FALSE\n",
    "- workingday: TRUE if neither a holiday nor a weekend, else FALSE\n",
    "- weathersit: categorical, \"Clear to partly cloudy\"/\"Light Precipitation\"/\"Misty\"\n",
    "- temp: normalized temperature in Celsius\n",
    "- atemp: normalized \"feeling\" temperature in Celsius\n",
    "- hum: normalized humidity\n",
    "- windspeed: normalized windspeed\n",
    "- instant: the time index -- number of hours since beginning of data set (not a variable)\n",
    "- mnth and yr: month and year indices (not variables)\n",
    "\n",
    "Remember that you must specify family = poisson or family = quasipoisson when using glm() to fit a count model.\n",
    "\n",
    "Since there are a lot of input variables, for convenience we will specify the outcome and the inputs in variables, and use paste() to assemble a string representing the model formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikesJuly is in the workspace\n",
    "str(bikesJuly)\n",
    "# 'data.frame':\t744 obs. of  12 variables:\n",
    "# $ hr        : Factor w/ 24 levels \"0\",\"1\",\"2\",\"3\",..: 1 2 3 4 5 6 7 8 9 10 ...\n",
    "# $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
    "# $ workingday: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
    "# $ weathersit: chr  \"Clear to partly cloudy\" \"Clear to partly cloudy\" \"Clear to partly cloudy\" \"Clear to partly cloudy\" ...\n",
    "# $ temp      : num  0.76 0.74 0.72 0.72 0.7 0.68 0.7 0.74 0.78 0.82 ...\n",
    "# $ atemp     : num  0.727 0.697 0.697 0.712 0.667 ...\n",
    "# $ hum       : num  0.66 0.7 0.74 0.84 0.79 0.79 0.79 0.7 0.62 0.56 ...\n",
    "# $ windspeed : num  0 0.1343 0.0896 0.1343 0.194 ...\n",
    "# $ cnt       : int  149 93 90 33 4 10 27 50 142 219 ...\n",
    "# $ instant   : int  13004 13005 13006 13007 13008 13009 13010 13011 13012 13013 ...\n",
    "# $ mnth      : int  7 7 7 7 7 7 7 7 7 7 ...\n",
    "# $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...\n",
    "\n",
    "# The outcome column\n",
    "outcome \n",
    "# [1] \"cnt\"\n",
    "\n",
    "# The inputs to use\n",
    "vars \n",
    "# [1] \"hr\"         \"holiday\"    \"workingday\" \"weathersit\" \"temp\"      \n",
    "# [6] \"atemp\"      \"hum\"        \"windspeed\"\n",
    "\n",
    "# Create the formula string for bikes rented as a function of the inputs\n",
    "(fmla <- paste(outcome, \"~\", paste(vars, collapse = \" + \")))\n",
    "# [1] \"cnt ~ hr + holiday + workingday + weathersit + temp + atemp + hum + windspeed\"\n",
    "\n",
    "# Calculate the mean and variance of the outcome\n",
    "(mean_bikes <- mean(bikesJuly[[outcome]]))\n",
    "# [1] 273.6653\n",
    "\n",
    "(var_bikes <- var(bikesJuly[[outcome]]))\n",
    "# [1] 45863.84\n",
    "\n",
    "# Fit the model\n",
    "bike_model <- glm(fmla, data = bikesJuly, family = \"quasipoisson\")\n",
    "\n",
    "# Call glance\n",
    "(perf <- glance(bike_model))\n",
    "#   null.deviance df.null logLik AIC BIC deviance df.residual\n",
    "# 1      133364.9     743     NA  NA  NA  28774.9         712\n",
    "\n",
    "# Calculate pseudo-R-squared\n",
    "# [1] 0.7842393\n",
    "(pseudoR2 <- 1 - perf$deviance / perf$null.deviance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict bike rentals on new data\n",
    "In this exercise you will use the model you built in the previous exercise to make predictions for the month of August. The data set bikesAugust has the same columns as bikesJuly.\n",
    "\n",
    "Recall that you must specify type = \"response\" with predict() when predicting counts from a glm poisson or quasipoisson model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikesAugust is in the workspace\n",
    "str(bikesAugust)\n",
    "\n",
    "# bike_model is in the workspace\n",
    "summary(bike_model)\n",
    "# Call:\n",
    "# glm(formula = fmla, family = quasipoisson, data = bikesJuly)\n",
    "\n",
    "# Deviance Residuals: \n",
    "#     Min        1Q    Median        3Q       Max  \n",
    "# -21.6117   -4.3121   -0.7223    3.5507   16.5079  \n",
    "\n",
    "# Coefficients:\n",
    "#                               Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)                    5.934986   0.439027  13.519  < 2e-16 ***\n",
    "# hr1                           -0.580055   0.193354  -3.000 0.002794 ** \n",
    "# hr2                           -0.892314   0.215452  -4.142 3.86e-05 ***\n",
    "# hr3                           -1.662342   0.290658  -5.719 1.58e-08 ***\n",
    "# hr4                           -2.350204   0.393560  -5.972 3.71e-09 ***\n",
    "# hr5                           -1.084289   0.230130  -4.712 2.96e-06 ***\n",
    "# hr6                            0.211945   0.156476   1.354 0.176012    \n",
    "# hr7                            1.211135   0.132332   9.152  < 2e-16 ***\n",
    "# hr8                            1.648361   0.127177  12.961  < 2e-16 ***\n",
    "# hr9                            1.155669   0.133927   8.629  < 2e-16 ***\n",
    "# hr10                           0.993913   0.137096   7.250 1.09e-12 ***\n",
    "# hr11                           1.116547   0.136300   8.192 1.19e-15 ***\n",
    "# hr12                           1.282685   0.134769   9.518  < 2e-16 ***\n",
    "# hr13                           1.273010   0.135872   9.369  < 2e-16 ***\n",
    "# hr14                           1.237721   0.136386   9.075  < 2e-16 ***\n",
    "# hr15                           1.260647   0.136144   9.260  < 2e-16 ***\n",
    "# hr16                           1.515893   0.132727  11.421  < 2e-16 ***\n",
    "# hr17                           1.948404   0.128080  15.212  < 2e-16 ***\n",
    "# hr18                           1.893915   0.127812  14.818  < 2e-16 ***\n",
    "# hr19                           1.669277   0.128471  12.993  < 2e-16 ***\n",
    "# hr20                           1.420732   0.131004  10.845  < 2e-16 ***\n",
    "# hr21                           1.146763   0.134042   8.555  < 2e-16 ***\n",
    "# hr22                           0.856182   0.138982   6.160 1.21e-09 ***\n",
    "# hr23                           0.479197   0.148051   3.237 0.001265 ** \n",
    "# holidayTRUE                    0.201598   0.079039   2.551 0.010961 *  \n",
    "# workingdayTRUE                 0.116798   0.033510   3.485 0.000521 ***\n",
    "# weathersitLight Precipitation -0.214801   0.072699  -2.955 0.003233 ** \n",
    "# weathersitMisty               -0.010757   0.038600  -0.279 0.780572    \n",
    "# temp                          -3.246001   1.148270  -2.827 0.004833 ** \n",
    "# atemp                          2.042314   0.953772   2.141 0.032589 *  \n",
    "# hum                           -0.748557   0.236015  -3.172 0.001581 ** \n",
    "# windspeed                      0.003277   0.148814   0.022 0.982439    \n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# (Dispersion parameter for quasipoisson family taken to be 38.98949)\n",
    "\n",
    "#     Null deviance: 133365  on 743  degrees of freedom\n",
    "# Residual deviance:  28775  on 712  degrees of freedom\n",
    "# AIC: NA\n",
    "\n",
    "# Number of Fisher Scoring iterations: 5\n",
    "\n",
    "# Make predictions on August data\n",
    "bikesAugust$pred  <- predict(bike_model, newdata = bikesAugust, type = \"response\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "bikesAugust %>% \n",
    "  mutate(residual = pred - cnt) %>%\n",
    "  summarize(rmse  = sqrt(mean(residual^2)))\n",
    "#       rmse\n",
    "# 1 112.5815\n",
    "\n",
    "# Plot predictions vs cnt (pred on x-axis)\n",
    "ggplot(bikesAugust, aes(x = pred, y = cnt)) +\n",
    "  geom_point() + \n",
    "  geom_abline(color = \"darkblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict_bike_rentals_on_new_data](./figures/predict_bike_rentals_on_new_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Bike Rental Predictions\n",
    "In the previous exercise, you visualized the bike model's predictions using the standard \"outcome vs. prediction\" scatter plot. Since the bike rental data is time series data, you might be interested in how the model performs as a function of time. In this exercise, you will compare the predictions and actual rentals on an hourly basis, for the first 14 days of August.\n",
    "\n",
    "To create the plot you will use the function tidyr::gather() to consolidate the predicted and actual values from bikesAugust in a single column. gather() takes as arguments:\n",
    "\n",
    "- The \"wide\" data frame to be gathered (implicit in a pipe)\n",
    "- The name of the key column to be created - contains the names of the gathered columns.\n",
    "- The name of the value column to be created - contains the values of the gathered columns.\n",
    "- The names of the columns to be gathered into a single column.\n",
    "\n",
    "You'll use the gathered data frame to compare the actual and predicted rental counts as a function of time. The time index, instant counts the number of observations since the beginning of data collection. The sample code converts the instants to daily units, starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions and cnt by date/time\n",
    "bikesAugust %>% \n",
    "  # set start to 0, convert unit to days\n",
    "  mutate(instant = (instant - min(instant))/24) %>%  \n",
    "  # gather cnt and pred into a value column\n",
    "  gather(key = valuetype, value = value, cnt, pred) %>%\n",
    "  filter(instant < 14) %>% # restric to first 14 days\n",
    "  # plot value by instant\n",
    "  ggplot(aes(x = instant, y = value, color = valuetype, linetype = valuetype)) + \n",
    "  geom_point() + \n",
    "  geom_line() + \n",
    "  scale_x_continuous(\"Day\", breaks = 0:14, labels = 0:14) + \n",
    "  scale_color_brewer(palette = \"Dark2\") + \n",
    "  ggtitle(\"Predicted August bike rentals, Quasipoisson model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualize_the_bike_rental_predictions](./figures/visualize_the_bike_rental_predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model soybean growth with GAM\n",
    "In this exercise you will model the average leaf weight on a soybean plant as a function of time (after planting). As you will see, the soybean plant doesn't grow at a steady rate, but rather has a \"growth spurt\" that eventually tapers off. Hence, leaf weight is not well described by a linear model.\n",
    "\n",
    "Recall that you can designate which variable you want to model non-linearly in a formula with the s() function:\n",
    "\n",
    "```\n",
    "y ~ s(x)\n",
    "```\n",
    "\n",
    "Also remember that gam() from the package mgcv has the calling interface\n",
    "\n",
    "```\n",
    "gam(formula, family, data)\n",
    "```\n",
    "\n",
    "For standard regression, use family = gaussian (the default).\n",
    "\n",
    "The soybean training data, soybean_train is loaded into your workspace. It has two columns: the outcome weight and the variable Time. For comparison, the linear model model.lin, which was fit using the formula weight ~ Time has already been loaded into the workspace as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soybean_train is in the workspace\n",
    "summary(soybean_train)\n",
    "\n",
    "# Plot weight vs Time (Time on x axis)\n",
    "ggplot(soybean_train, aes(x = Time, y = Weight)) + \n",
    "  geom_point() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model_soybean_growth_with_GAM](./figures/model_soybean_growth_with_GAM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "library(mgcv)\n",
    "fmla.gam <- weight ~ s(Time)\n",
    "model.gam <- gam(fmla.gam, data = soybean_train, family = gaussian)\n",
    "\n",
    "# Call summary() on model.lin and look for R-squared\n",
    "summary(model.lin)\n",
    "# Call:\n",
    "# lm(formula = fmla.lin, data = soybean_train)\n",
    "\n",
    "# Residuals:\n",
    "#     Min      1Q  Median      3Q     Max \n",
    "# -9.3933 -1.7100 -0.3909  1.9056 11.4381 \n",
    "\n",
    "# Coefficients:\n",
    "#              Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept) -6.559283   0.358527  -18.30   <2e-16 ***\n",
    "# Time         0.292094   0.007444   39.24   <2e-16 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 2.778 on 328 degrees of freedom\n",
    "# Multiple R-squared:  0.8244,\tAdjusted R-squared:  0.8238 \n",
    "# F-statistic:  1540 on 1 and 328 DF,  p-value: < 2.2e-16\n",
    "\n",
    "# Call summary() on model.gam and look for R-squared\n",
    "summary(model.gam)\n",
    "# Family: gaussian \n",
    "# Link function: identity \n",
    "\n",
    "# Formula:\n",
    "# weight ~ s(Time)\n",
    "\n",
    "# Parametric coefficients:\n",
    "#             Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)   6.1645     0.1143   53.93   <2e-16 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Approximate significance of smooth terms:\n",
    "#           edf Ref.df     F p-value    \n",
    "# s(Time) 8.495   8.93 338.2  <2e-16 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# R-sq.(adj) =  0.902   Deviance explained = 90.4%\n",
    "# GCV = 4.4395  Scale est. = 4.3117    n = 330\n",
    "\n",
    "# Call plot() on model.gam\n",
    "plot(model.gam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model_soybean_growth_with_GAM_2](./figures/model_soybean_growth_with_GAM_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with the soybean model on test data\n",
    "In this exercise you will apply the soybean models from the previous exercise (model.lin and model.gam, already in your workspace) to new data: soybean_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soybean_test is in the workspace\n",
    "summary(soybean_test)\n",
    "#      Plot    Variety   Year         Time           weight       \n",
    "#  1988F8 : 4   F:43    1988:32   Min.   :14.00   Min.   : 0.0380  \n",
    "#  1988P7 : 4   P:39    1989:26   1st Qu.:23.00   1st Qu.: 0.4248  \n",
    "#  1989F8 : 4           1990:24   Median :41.00   Median : 3.0025  \n",
    "#  1990F8 : 4                     Mean   :44.09   Mean   : 7.1576  \n",
    "#  1988F4 : 3                     3rd Qu.:69.00   3rd Qu.:15.0113  \n",
    "#  1988F2 : 3                     Max.   :84.00   Max.   :30.2717  \n",
    "#  (Other):60\n",
    "\n",
    "# Get predictions from linear model\n",
    "soybean_test$pred.lin <- predict(model.lin, newdata = soybean_test)\n",
    "\n",
    "# Get predictions from gam model\n",
    "soybean_test$pred.gam <- as.numeric(predict(model.gam, newdata = soybean_test))\n",
    "\n",
    "# Gather the predictions into a \"long\" dataset\n",
    "soybean_long <- soybean_test %>%\n",
    "  gather(key = modeltype, value = pred, pred.lin, pred.gam)\n",
    "\n",
    "# Calculate the rmse\n",
    "soybean_long %>%\n",
    "  mutate(residual = weight - pred) %>%     # residuals\n",
    "  group_by(modeltype) %>%                  # group by modeltype\n",
    "  summarize(rmse = sqrt(mean(residual^2))) # calculate the RMSE\n",
    "# # A tibble: 2 x 2\n",
    "#   modeltype  rmse\n",
    "#   <chr>     <dbl>\n",
    "# 1 pred.gam   2.29\n",
    "# 2 pred.lin   3.19\n",
    "\n",
    "# Compare the predictions against actual weights on the test data\n",
    "soybean_long %>%\n",
    "  ggplot(aes(x = Time)) +                          # the column for the x axis\n",
    "  geom_point(aes(y = weight)) +                    # the y-column for the scatterplot\n",
    "  geom_point(aes(y = pred, color = modeltype)) +   # the y-column for the point-and-line plot\n",
    "  geom_line(aes(y = pred, color = modeltype, linetype = modeltype)) + # the y-column for the point-and-line plot\n",
    "  scale_color_brewer(palette = \"Dark2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict_with_the_soybean_model_on_test_data](./figures/predict_with_the_soybean_model_on_test_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a random forest model for bike rentals\n",
    "In this exercise you will again build a model to predict the number of bikes rented in an hour as a function of the weather, the type of day (holiday, working day, or weekend), and the time of day. You will train the model on data from the month of July.\n",
    "\n",
    "You will use the ranger package to fit the random forest model. For this exercise, the key arguments to the ranger() call are:\n",
    "\n",
    "- formula\n",
    "- data\n",
    "- num.trees: the number of trees in the forest.\n",
    "- respect.unordered.factors : Specifies how to treat unordered factor variables. We recommend setting this to \"order\" for regression.\n",
    "- seed: because this is a random algorithm, you will set the seed to get reproducible results\n",
    "\n",
    "Since there are a lot of input variables, for convenience we will specify the outcome and the inputs in the variables outcome and vars, and use paste() to assemble a string representing the model formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikesJuly is in the workspace\n",
    "str(bikesJuly)\n",
    "# 'data.frame':\t744 obs. of  12 variables:\n",
    "#  $ hr        : Factor w/ 24 levels \"0\",\"1\",\"2\",\"3\",..: 1 2 3 4 5 6 7 8 9 10 ...\n",
    "#  $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
    "#  $ workingday: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
    "#  $ weathersit: chr  \"Clear to partly cloudy\" \"Clear to partly cloudy\" \"Clear to partly cloudy\" \"Clear to partly cloudy\" ...\n",
    "#  $ temp      : num  0.76 0.74 0.72 0.72 0.7 0.68 0.7 0.74 0.78 0.82 ...\n",
    "#  $ atemp     : num  0.727 0.697 0.697 0.712 0.667 ...\n",
    "#  $ hum       : num  0.66 0.7 0.74 0.84 0.79 0.79 0.79 0.7 0.62 0.56 ...\n",
    "#  $ windspeed : num  0 0.1343 0.0896 0.1343 0.194 ...\n",
    "#  $ cnt       : int  149 93 90 33 4 10 27 50 142 219 ...\n",
    "#  $ instant   : int  13004 13005 13006 13007 13008 13009 13010 13011 13012 13013 ...\n",
    "#  $ mnth      : int  7 7 7 7 7 7 7 7 7 7 ...\n",
    "#  $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...\n",
    "\n",
    "# Random seed to reproduce results\n",
    "seed\n",
    "# [1] 423563\n",
    "\n",
    "# the outcome column\n",
    "(outcome <- \"cnt\")\n",
    "# [1] \"cnt\"\n",
    "\n",
    "# The input variables\n",
    "(vars <- c(\"hr\", \"holiday\", \"workingday\", \"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\"))\n",
    "# [1] \"hr\"         \"holiday\"    \"workingday\" \"weathersit\" \"temp\"      \n",
    "# [6] \"atemp\"      \"hum\"        \"windspeed\"\n",
    "\n",
    "# Create the formula string for bikes rented as a function of the inputs\n",
    "(fmla <- paste(outcome, \"~\", paste(vars, collapse = \" + \")))\n",
    "#[1] \"cnt ~ hr + holiday + workingday + weathersit + temp + atemp + hum + windspeed\"\n",
    "\n",
    "# Load the package ranger\n",
    "library(ranger)\n",
    "\n",
    "# Fit and print the random forest model.\n",
    "(bike_model_rf <- ranger(fmla, \n",
    "                         bikesJuly, \n",
    "                         num.trees = 500, \n",
    "                         respect.unordered.factors = \"order\", \n",
    "                         seed = seed))\n",
    "# Ranger result\n",
    "\n",
    "# Call:\n",
    "#  ranger(fmla, bikesJuly, num.trees = 500, respect.unordered.factors = \"order\",      seed = seed) \n",
    "\n",
    "# Type:                             Regression \n",
    "# Number of trees:                  500 \n",
    "# Sample size:                      744 \n",
    "# Number of independent variables:  8 \n",
    "# Mtry:                             2 \n",
    "# Target node size:                 5 \n",
    "# Variable importance mode:         none \n",
    "# Splitrule:                        variance \n",
    "# OOB prediction error (MSE):       8230.568 \n",
    "# R squared (OOB):                  0.8205434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict bike rentals with the random forest model\n",
    "In this exercise you will use the model that you fit in the previous exercise to predict bike rentals for the month of August.\n",
    "\n",
    "The predict() function for a ranger model produces a list. One of the elements of this list is predictions, a vector of predicted values. You can access predictions with the $ notation for accessing named elements of a list:\n",
    "\n",
    "```\n",
    "predict(model, data)$predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the August data\n",
    "bikesAugust$pred <- predict(bike_model_rf, bikesAugust)$predictions\n",
    "\n",
    "# Calculate the RMSE of the predictions\n",
    "bikesAugust %>% \n",
    "  mutate(residual = cnt - pred)  %>% # calculate the residual\n",
    "  summarize(rmse  = sqrt(mean(residual^2)))      # calculate rmse\n",
    "#       rmse\n",
    "# 1 96.66032\n",
    "\n",
    "# Plot actual outcome vs predictions (predictions on x-axis)\n",
    "ggplot(bikesAugust, aes(x = pred, y = cnt)) + \n",
    "  geom_point() + \n",
    "  geom_abline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict_bike_rentals_with_the_random_forest_model](./figures/predict_bike_rentals_with_the_random_forest_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize random forest bike model predictions\n",
    "In the previous exercise, you saw that the random forest bike model did better on the August data than the quasiposson model, in terms of RMSE.\n",
    "\n",
    "In this exercise you will visualize the random forest model's August predictions as a function of time. The corresponding plot from the quasipoisson model that you built in a previous exercise is in the workspace for you to compare.\n",
    "\n",
    "Recall that the quasipoisson model mostly identified the pattern of slow and busy hours in the day, but it somewhat underestimated peak demands. You would like to see how the random forest model compares.\n",
    "\n",
    "The data frame bikesAugust (with predictions) is in the workspace. The plot quasipoisson_plot of quasipoisson model predictions as a function of time is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_two_weeks <- bikesAugust %>% \n",
    "  # Set start to 0, convert unit to days\n",
    "  mutate(instant = (instant - min(instant)) / 24) %>% \n",
    "  # Gather cnt and pred into a column named value with key valuetype\n",
    "  gather(key = valuetype, value = value, cnt, pred) %>%\n",
    "  # Filter for rows in the first two\n",
    "  filter(instant < 14) \n",
    "\n",
    "# Plot predictions and cnt by date/time \n",
    "ggplot(first_two_weeks, aes(x = instant, y = value, color = valuetype, linetype = valuetype)) + \n",
    "  geom_point() + \n",
    "  geom_line() + \n",
    "  scale_x_continuous(\"Day\", breaks = 0:14, labels = 0:14) + \n",
    "  scale_color_brewer(palette = \"Dark2\") + \n",
    "  ggtitle(\"Predicted August bike rentals, Random Forest plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualize_random_forest_bike_model_predictions](./figures/visualize_random_forest_bike_model_predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vtreat on a small example\n",
    "In this exercise you will use vtreat to one-hot-encode a categorical variable on a small example. vtreat creates a treatment plan to transform categorical variables into indicator variables (coded \"lev\"), and to clean bad values out of numerical variables (coded \"clean\").\n",
    "\n",
    "To design a treatment plan use the function designTreatmentsZ()\n",
    "\n",
    "```\n",
    "treatplan <- designTreatmentsZ(data, varlist)\n",
    "```\n",
    "\n",
    "- data: the original training data frame\n",
    "- varlist: a vector of input variables to be treated (as strings).\n",
    "\n",
    "designTreatmentsZ() returns a list with an element scoreFrame: a data frame that includes the names and types of the new variables:\n",
    "\n",
    "```\n",
    "scoreFrame <- treatplan %>% \n",
    "            magrittr::use_series(scoreFrame) %>% \n",
    "            select(varName, origName, code)\n",
    "```\n",
    "\n",
    "- varName: the name of the new treated variable\n",
    "- origName: the name of the original variable that the treated variable comes from\n",
    "- code: the type of the new variable.\n",
    "    - \"clean\": a numerical variable with no NAs or NaNs\n",
    "    - \"lev\": an indicator variable for a specific level of the original categorical variable.\n",
    "    \n",
    "(magrittr::use_series() is an alias for $ that you can use in pipes.)\n",
    "\n",
    "For these exercises, we want varName where code is either \"clean\" or \"lev\":\n",
    "\n",
    "```\n",
    "newvarlist <- scoreFrame %>% \n",
    "             filter(code %in% c(\"clean\", \"lev\") %>%\n",
    "             magrittr::use_series(varName)\n",
    "```\n",
    "\n",
    "To transform the data set into all numerical and one-hot-encoded variables, use prepare():\n",
    "\n",
    "```\n",
    "data.treat <- prepare(treatplan, data, varRestrictions = newvarlist)\n",
    "```\n",
    "- treatplan: the treatment plan\n",
    "- data: the data frame to be treated\n",
    "- varRestrictions: the variables desired in the treated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dframe is in the workspace\n",
    "dframe\n",
    "#   color size popularity\n",
    "# 1      b   13  1.0785088\n",
    "# 2      r   11  1.3956245\n",
    "# 3      r   15  0.9217988\n",
    "# 4      r   14  1.2025453\n",
    "# 5      r   13  1.0838662\n",
    "# 6      b   11  0.8043527\n",
    "# 7      r    9  1.1035440\n",
    "# 8      g   12  0.8746332\n",
    "# 9      b    7  0.6947058\n",
    "# 10     b   12  0.8832502\n",
    "\n",
    "# Create and print a vector of variable names\n",
    "(vars <- c(\"color\", \"size\"))\n",
    "# [1] \"color\" \"size\"\n",
    "\n",
    "# Load the package vtreat\n",
    "library(vtreat)\n",
    "\n",
    "# Create the treatment plan\n",
    "treatplan <- designTreatmentsZ(dframe, vars)\n",
    "# [1] \"vtreat 1.2.0 inspecting inputs Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \"designing treatments Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \" have initial level statistics Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \"design var color Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \"design var size Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \" scoring treatments Sat Feb  8 09:34:11 2020\"\n",
    "# [1] \"have treatment plan Sat Feb  8 09:34:11 2020\"\n",
    "\n",
    "# Examine the scoreFrame\n",
    "(scoreFrame <- treatplan %>%\n",
    "    use_series(scoreFrame) %>%\n",
    "    select(varName, origName, code))\n",
    "#         varName origName  code\n",
    "# 1    color_catP    color  catP\n",
    "# 2    size_clean     size clean\n",
    "# 3 color_lev_x_b    color   lev\n",
    "# 4 color_lev_x_g    color   lev\n",
    "# 5 color_lev_x_r    color   lev\n",
    "# We only want the rows with codes \"clean\" or \"lev\"\n",
    "(newvars <- scoreFrame %>%\n",
    "    filter(code %in% c(\"clean\", \"lev\")) %>%\n",
    "    use_series(varName))\n",
    "# [1] \"size_clean\"    \"color_lev_x_b\" \"color_lev_x_g\" \"color_lev_x_r\"\n",
    "\n",
    "# Create the treated training data\n",
    "(dframe.treat <- prepare(treatplan, dframe, varRestriction = newvars))\n",
    "#   size_clean color_lev_x_b color_lev_x_g color_lev_x_r\n",
    "# 1          13             1             0             0\n",
    "# 2          11             0             0             1\n",
    "# 3          15             0             0             1\n",
    "# 4          14             0             0             1\n",
    "# 5          13             0             0             1\n",
    "# 6          11             1             0             0\n",
    "# 7           9             0             0             1\n",
    "# 8          12             0             1             0\n",
    "# 9           7             1             0             0\n",
    "# 10         12             1             0             0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Novel levels\n",
    "When a level of a categorical variable is rare, sometimes it will fail to show up in training data. If that rare level then appears in future data, downstream models may not know what to do with it. When such novel levels appear, using model.matrix or caret::dummyVars to one-hot-encode will not work correctly.\n",
    "\n",
    "vtreat is a \"safer\" alternative to model.matrix for one-hot-encoding, because it can manage novel levels safely. vtreat also manages missing values in the data (both categorical and continuous).\n",
    "\n",
    "In this exercise you will see how vtreat handles categorical values that did not appear in the training set. The treatment plan treatplan and the set of variables newvars from the previous exercise are still in your workspace. dframe and a new data frame testframe are also in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print testframe\n",
    "testframe\n",
    "#   color size popularity\n",
    "# 1      g    7  0.9733920\n",
    "# 2      g    8  0.9122529\n",
    "# 3      y   10  1.4217153\n",
    "# 4      g   12  1.1905828\n",
    "# 5      g    6  0.9866464\n",
    "# 6      y    8  1.3697515\n",
    "# 7      b   12  1.0959387\n",
    "# 8      g   12  0.9161547\n",
    "# 9      g   12  1.0000460\n",
    "# 10     r    8  1.3137360\n",
    "\n",
    "# Use prepare() to one-hot-encode testframe\n",
    "(testframe.treat <- prepare(treatplan, testframe, varRestriction = newvars))\n",
    "#   size_clean color_lev_x_b color_lev_x_g color_lev_x_r\n",
    "# 1           7             0             1             0\n",
    "# 2           8             0             1             0\n",
    "# 3          10             0             0             0\n",
    "# 4          12             0             1             0\n",
    "# 5           6             0             1             0\n",
    "# 6           8             0             0             0\n",
    "# 7          12             1             0             0\n",
    "# 8          12             0             1             0\n",
    "# 9          12             0             1             0\n",
    "# 10          8             0             0             1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vtreat the bike rental data\n",
    "In this exercise you will create one-hot-encoded data frames of the July/August bike data, for use with xgboost later on.\n",
    "\n",
    "The data frames bikesJuly and bikesAugust are in the workspace.\n",
    "\n",
    "For your convenience, we have defined the variable vars with the list of variable columns for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outcome column\n",
    "(outcome <- \"cnt\")\n",
    "\n",
    "# The input columns\n",
    "(vars <- c(\"hr\", \"holiday\", \"workingday\", \"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\"))\n",
    "\n",
    "# Load the package vtreat\n",
    "library(vtreat)\n",
    "\n",
    "# Create the treatment plan from bikesJuly (the training data)\n",
    "treatplan <- designTreatmentsZ(bikesJuly, vars, verbose = FALSE)\n",
    "\n",
    "# Get the \"clean\" and \"lev\" variables from the scoreFrame\n",
    "(newvars <- treatplan %>%\n",
    "  use_series(scoreFrame) %>%        \n",
    "  filter(code %in% c(\"clean\", \"lev\")) %>%  # get the rows you care about\n",
    "  use_series(varName))           # get the varName column\n",
    "\n",
    "# Prepare the training data\n",
    "bikesJuly.treat <- prepare(treatplan, bikesJuly,  varRestriction = newvars)\n",
    "\n",
    "# Prepare the test data\n",
    "bikesAugust.treat <- prepare(treatplan, bikesAugust,  varRestriction = newvars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:CHIAPETR]",
   "language": "R",
   "name": "conda-env-CHIAPETR-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
