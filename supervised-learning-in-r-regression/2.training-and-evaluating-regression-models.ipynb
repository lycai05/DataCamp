{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphically evaluate the unemployment model\n",
    "In this exercise you will graphically evaluate the unemployment model, unemployment_model, that you fit to the unemployment data in the previous chapter. Recall that the model predicts female_unemployment from male_unemployment.\n",
    "\n",
    "You will plot the model's predictions against the actual female_unemployment; recall the command is of the form\n",
    "\n",
    "```\n",
    "ggplot(dframe, aes(x = pred, y = outcome)) + \n",
    "       geom_point() +  \n",
    "       geom_abline()\n",
    "```\n",
    "Then you will calculate the residuals:\n",
    "\n",
    "```\n",
    "residuals <- actual outcome - predicted outcome\n",
    "```\n",
    "\n",
    "and plot predictions against residuals. The residual graph will take a slightly different form: you compare the residuals to the horizontal line x=0 (using geom_hline()) rather than to the line x=y. The command will be provided.\n",
    "\n",
    "The data frame unemployment and model unemployment_model are available in the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear_reg_3](./figures/linear_reg_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gain curve to evaluate the unemployment model\n",
    "In the previous exercise you made predictions about female_unemployment and visualized the predictions and the residuals. Now, you will also plot the gain curve of the unemployment_model's predictions against actual female_unemployment using the WVPlots::GainCurvePlot() function.\n",
    "\n",
    "For situations where order is more important than exact values, the gain curve helps you check if the model's predictions sort in the same order as the true outcome.\n",
    "\n",
    "Calls to the function GainCurvePlot() look like:\n",
    "\n",
    "```\n",
    "GainCurvePlot(frame, xvar, truthvar, title)\n",
    "```\n",
    "where\n",
    "\n",
    "frame is a data frame <br>\n",
    "xvar and truthvar are strings naming the prediction and actual outcome columns of frame <br>\n",
    "title is the title of the plot \n",
    "When the predictions sort in exactly the same order, the relative Gini coefficient is 1. When the model sorts poorly, the relative Gini coefficient is close to zero, or even negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the package WVPlots\n",
    "library(WVPlots)\n",
    "\n",
    "# Plot the Gain Curve\n",
    "GainCurvePlot(unemployment, \"predictions\", \"female_unemployment\", \"Unemployment model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear_reg_4](./figures/linear_reg_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate RMSE\n",
    "In this exercise you will calculate the RMSE of your unemployment model. In the previous coding exercises, you added two columns to the unemployment dataset:\n",
    "\n",
    "the model's predictions (predictions column)\n",
    "the residuals between the predictions and the outcome (residuals column)\n",
    "You can calculate the RMSE from a vector of residuals, res, as:\n",
    "```\n",
    "RMSE=sqrt(mean(res^2))\n",
    "```\n",
    "You want RMSE to be small. How small is \"small\"? One heuristic is to compare the RMSE to the standard deviation of the outcome. With a good model, the RMSE should be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unemployment is in the workspace\n",
    "summary(unemployment)\n",
    "\n",
    "# For convenience put the residuals in the variable res\n",
    "res <- unemployment$predictions - unemployment$female_unemployment\n",
    "\n",
    "# Calculate RMSE, assign it to the variable rmse and print it\n",
    "(rmse <- sqrt(mean(res^2)))\n",
    "# [1] 0.5337612\n",
    "\n",
    "# Calculate the standard deviation of female_unemployment and print it\n",
    "(sd_unemployment <- sd(unemployment$female_unemployment))\n",
    "# [1] 1.314271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate R-Squared\n",
    "Now that you've calculated the RMSE of your model's predictions, you will examine how well the model fits the data: that is, how much variance does it explain. You can do this using R^2.\n",
    "\n",
    "Suppose y is the true outcome, p is the prediction from the model, and res=y−p are the residuals of the predictions.\n",
    "\n",
    "Then the total sum of squares tss (\"total variance\") of the data is:\n",
    "\n",
    "```\n",
    "tss=sum(y - y_hat)^2\n",
    "```\n",
    "where y_hat is the mean value of y.\n",
    "\n",
    "The residual sum of squared errors of the model, rss is:\n",
    "```\n",
    "rss=sum(res^2)\n",
    "```\n",
    "R^2 (R-Squared), the \"variance explained\" by the model, is then:\n",
    "\n",
    "1−rss/tss\n",
    "After you calculate R^2, you will compare what you computed with the R^2 reported by glance(). glance() returns a one-row data frame; for a linear regression model, one of the columns returned is the R^2 of the model on the training data.\n",
    "\n",
    "The data frame unemployment is in your workspace, with the columns predictions and residuals that you calculated in a previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean female_unemployment: fe_mean. Print it\n",
    "(fe_mean <- mean(unemployment$female_unemployment))\n",
    "# [1] 5.569231\n",
    "\n",
    "# Calculate total sum of squares: tss. Print it\n",
    "(tss <- sum((unemployment$female_unemployment - fe_mean)^2))\n",
    "# [1] 20.72769\n",
    "\n",
    "# Calculate residual sum of squares: rss. Print it\n",
    "(rss <- sum(unemployment$residuals^2))\n",
    "# [1] 3.703714\n",
    "\n",
    "# Calculate R-squared: rsq. Print it. Is it a good fit?\n",
    "(rsq <- 1 - rss / tss)\n",
    "# [1] 0.8213157\n",
    "\n",
    "# Get R-squared from glance. Print it\n",
    "(rsq_glance <- glance(unemployment_model)$r.squared)\n",
    "# [1] 0.8213157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation and R-squared\n",
    "The linear correlation of two variables, x and y, measures the strength of the linear relationship between them. When x and y are respectively:\n",
    "\n",
    "- the outcomes of a regression model that minimizes squared-error (like linear regression) and\n",
    "- the true outcomes of the training data\n",
    "\n",
    "then the square of the correlation is the same as R^2. You will verify that in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlation between the prediction and true outcome: rho and print it\n",
    "(rho <- cor(unemployment$prediction, unemployment$female_unemployment))\n",
    "\n",
    "# Square rho: rho2 and print it\n",
    "(rho2 <- rho^2)\n",
    "# [1] 0.8213157\n",
    "\n",
    "# Get R-squared from glance and print it\n",
    "(rsq_glance <- glance(unemployment_model)$r.squared)\n",
    "# [1] 0.8213157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a random test/train split\n",
    "For the next several exercises you will use the mpg data from the package ggplot2. The data describes the characteristics of several makes and models of cars from different years. The goal is to predict city fuel efficiency from highway fuel efficiency.\n",
    "\n",
    "In this exercise, you will split mpg into a training set mpg_train (75% of the data) and a test set mpg_test (25% of the data). One way to do this is to generate a column of uniform random numbers between 0 and 1, using the function runif().\n",
    "\n",
    "If you have a data set dframe of size N, and you want a random subset of approximately size 100∗X% of N (where X is between 0 and 1), then:\n",
    "\n",
    "Generate a vector of uniform random numbers: gp = runif(N).\n",
    "dframe[gp < X,] will be about the right size.\n",
    "dframe[gp >= X,] will be the complement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg is in the workspace\n",
    "summary(mpg)\n",
    "#  manufacturer          model               displ            year     \n",
    "#  Length:234         Length:234         Min.   :1.600   Min.   :1999  \n",
    "#  Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999  \n",
    "#  Mode  :character   Mode  :character   Median :3.300   Median :2004  \n",
    "#                                        Mean   :3.472   Mean   :2004  \n",
    "#                                        3rd Qu.:4.600   3rd Qu.:2008  \n",
    "#                                        Max.   :7.000   Max.   :2008  \n",
    "#       cyl           trans               drv                 cty       \n",
    "#  Min.   :4.000   Length:234         Length:234         Min.   : 9.00  \n",
    "#  1st Qu.:4.000   Class :character   Class :character   1st Qu.:14.00  \n",
    "#  Median :6.000   Mode  :character   Mode  :character   Median :17.00  \n",
    "#  Mean   :5.889                                         Mean   :16.86  \n",
    "#  3rd Qu.:8.000                                         3rd Qu.:19.00  \n",
    "#  Max.   :8.000                                         Max.   :35.00  \n",
    "#       hwy             fl               class          \n",
    "#  Min.   :12.00   Length:234         Length:234        \n",
    "#  1st Qu.:18.00   Class :character   Class :character  \n",
    "#  Median :24.00   Mode  :character   Mode  :character  \n",
    "#  Mean   :23.44                                        \n",
    "#  3rd Qu.:27.00                                        \n",
    "#  Max.   :44.00\n",
    "dim(mpg)\n",
    "# [1] 234  11\n",
    "\n",
    "# Use nrow to get the number of rows in mpg (N) and print it\n",
    "(N <- nrow(mpg))\n",
    "# [1] 234\n",
    "\n",
    "# Calculate how many rows 75% of N should be and print it\n",
    "# Hint: use round() to get an integer\n",
    "(target <- round(N * 0.75))\n",
    "\n",
    "# Create the vector of N uniform random variables: gp\n",
    "gp <- runif(N)\n",
    "\n",
    "# Use gp to create the training set: mpg_train (75% of data) and mpg_test (25% of data)\n",
    "mpg_train <- mpg[gp < 0.75, ]\n",
    "mpg_test <- mpg[gp >= 0.75, ]\n",
    "\n",
    "# Use nrow() to examine mpg_train and mpg_test\n",
    "nrow(mpg_train)\n",
    "# [1] 175\n",
    "nrow(mpg_test)\n",
    "# [1] 59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model using test/train split\n",
    "Now that you have split the mpg dataset into mpg_train and mpg_test, you will use mpg_train to train a model to predict city fuel efficiency (cty) from highway fuel efficiency (hwy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg_train is in the workspace\n",
    "summary(mpg_train)\n",
    "#  manufacturer          model               displ            year     \n",
    "#  Length:180         Length:180         Min.   :1.600   Min.   :1999  \n",
    "#  Class :character   Class :character   1st Qu.:2.500   1st Qu.:1999  \n",
    "#  Mode  :character   Mode  :character   Median :3.400   Median :2008  \n",
    "#                                        Mean   :3.558   Mean   :2004  \n",
    "#                                        3rd Qu.:4.600   3rd Qu.:2008  \n",
    "#                                        Max.   :7.000   Max.   :2008  \n",
    "#       cyl           trans               drv                 cty       \n",
    "#  Min.   :4.000   Length:180         Length:180         Min.   : 9.00  \n",
    "#  1st Qu.:4.000   Class :character   Class :character   1st Qu.:14.00  \n",
    "#  Median :6.000   Mode  :character   Mode  :character   Median :16.00  \n",
    "#  Mean   :6.022                                         Mean   :16.58  \n",
    "#  3rd Qu.:8.000                                         3rd Qu.:19.00  \n",
    "#  Max.   :8.000                                         Max.   :33.00  \n",
    "#       hwy             fl               class          \n",
    "#  Min.   :12.00   Length:180         Length:180        \n",
    "#  1st Qu.:18.00   Class :character   Class :character  \n",
    "#  Median :24.00   Mode  :character   Mode  :character  \n",
    "#  Mean   :23.11                                        \n",
    "#  3rd Qu.:27.00                                        \n",
    "#  Max.   :44.00\n",
    "\n",
    "# Create a formula to express cty as a function of hwy: fmla and print it.\n",
    "(fmla <- cty ~ hwy)\n",
    "# cty ~ hwy\n",
    "\n",
    "# Now use lm() to build a model mpg_model from mpg_train that predicts cty from hwy \n",
    "mpg_model <- lm(fmla, mpg_train)\n",
    "\n",
    "# Use summary() to examine the model\n",
    "summary(mpg_model)\n",
    "# Call:\n",
    "# lm(formula = fmla, data = mpg_train)\n",
    "\n",
    "# Residuals:\n",
    "#     Min      1Q  Median      3Q     Max \n",
    "# -2.8400 -0.8305 -0.1551  0.5865  4.8140 \n",
    "\n",
    "# Coefficients:\n",
    "#             Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)  1.13375    0.38309   2.959   0.0035 ** \n",
    "# hwy          0.66825    0.01608  41.564   <2e-16 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 1.251 on 178 degrees of freedom\n",
    "# Multiple R-squared:  0.9066,\tAdjusted R-squared:  0.9061 \n",
    "# F-statistic:  1728 on 1 and 178 DF,  p-value: < 2.2e-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a model using test/train split\n",
    "Now you will test the model mpg_model on the test data, mpg_test. Functions rmse() and r_squared() to calculate RMSE and R-squared have been provided for convenience:\n",
    "\n",
    "```\n",
    "rmse(predcol, ycol)\n",
    "r_squared(predcol, ycol)\n",
    "```\n",
    "where:\n",
    "\n",
    "predcol: The predicted values\n",
    "ycol: The actual outcome\n",
    "You will also plot the predictions vs. the outcome.\n",
    "\n",
    "Generally, model performance is better on the training data than the test data (though sometimes the test set \"gets lucky\"). A slight difference in performance is okay; if the performance on training is significantly better, there is a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict cty from hwy for the training set\n",
    "mpg_train$pred <- predict(mpg_model, mpg_train)\n",
    "\n",
    "# predict cty from hwy for the test set\n",
    "mpg_test$pred <- predict(mpg_model, mpg_test)\n",
    "\n",
    "# Evaluate the rmse on both training and test data and print them\n",
    "(rmse_train <- rmse(mpg_train$pred, mpg_train$cty))\n",
    "# [1] 1.243958\n",
    "(rmse_test <- rmse(mpg_test$pred, mpg_test$cty))\n",
    "# [1] 1.277228\n",
    "\n",
    "# Evaluate the r-squared on both training and test data.and print them\n",
    "(rsq_train <- r_squared(mpg_train$pred, mpg_train$cty))\n",
    "# [1] 0.9065908\n",
    "(rsq_test <- r_squared(mpg_test$pred, mpg_test$cty))\n",
    "# [1] 0.9251412\n",
    "\n",
    "# Plot the predictions (on the x-axis) against the outcome (cty) on the test data\n",
    "ggplot(mpg_test, aes(x = pred, y = cty)) + \n",
    "  geom_point() + \n",
    "  geom_abline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linear_reg_5](./figures/linear_reg_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross validation plan\n",
    "There are several ways to implement an n-fold cross validation plan. In this exercise you will create such a plan using vtreat::kWayCrossValidation(), and examine it.\n",
    "\n",
    "kWayCrossValidation() creates a cross validation plan with the following call:\n",
    "\n",
    "```\n",
    "splitPlan <- kWayCrossValidation(nRows, nSplits, dframe, y)\n",
    "```\n",
    "where nRows is the number of rows of data to be split, and nSplits is the desired number of cross-validation folds.\n",
    "\n",
    "Strictly speaking, dframe and y aren't used by kWayCrossValidation; they are there for compatibility with other vtreat data partitioning functions. You can set them both to NULL.\n",
    "\n",
    "The resulting splitPlan is a list of nSplits elements; each element contains two vectors:\n",
    "\n",
    "train: the indices of dframe that will form the training set\n",
    "app: the indices of dframe that will form the test (or application) set\n",
    "In this exercise you will create a 3-fold cross-validation plan for the data set mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the package vtreat\n",
    "library(vtreat)\n",
    "\n",
    "# Get the number of rows in mpg\n",
    "nRows <- nrow(mpg)\n",
    "\n",
    "# Implement the 3-fold cross-fold plan with vtreat\n",
    "splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)\n",
    "# List of 3\n",
    "#  $ :List of 2\n",
    "#   ..$ train: int [1:156] 2 3 4 6 8 9 12 13 14 15 ...\n",
    "#   ..$ app  : int [1:78] 189 208 125 155 181 97 173 148 227 45 ...\n",
    "#  $ :List of 2\n",
    "#   ..$ train: int [1:156] 1 3 4 5 7 8 9 10 11 13 ...\n",
    "#   ..$ app  : int [1:78] 180 183 91 34 166 143 100 195 153 25 ...\n",
    "#  $ :List of 2\n",
    "#   ..$ train: int [1:156] 1 2 5 6 7 10 11 12 15 17 ...\n",
    "#   ..$ app  : int [1:78] 105 178 76 168 22 158 101 129 14 188 ...\n",
    "#  - attr(*, \"splitmethod\")= chr \"kwaycross\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate a modeling procedure using n-fold cross-validation\n",
    "In this exercise you will use splitPlan, the 3-fold cross validation plan from the previous exercise, to make predictions from a model that predicts mpg$cty from mpg$hwy.\n",
    "\n",
    "If dframe is the training data, then one way to add a column of cross-validation predictions to the frame is as follows:\n",
    "\n",
    "```\n",
    "# Initialize a column of the appropriate length\n",
    "dframe$pred.cv <- 0 \n",
    "\n",
    "# k is the number of folds\n",
    "# splitPlan is the cross validation plan\n",
    "\n",
    "for(i in 1:k) {\n",
    "  # Get the ith split\n",
    "  split <- splitPlan[[i]]\n",
    "\n",
    "  # Build a model on the training data \n",
    "  # from this split \n",
    "  # (lm, in this case)\n",
    "  model <- lm(fmla, data = dframe[split$train,])\n",
    "\n",
    "  # make predictions on the \n",
    "  # application data from this split\n",
    "  dframe$pred.cv[split$app] <- predict(model, newdata = dframe[split$app,])\n",
    "}\n",
    "```\n",
    "\n",
    "Cross-validation predicts how well a model built from all the data will perform on new data. As with the test/train split, for a good modeling procedure, cross-validation performance and training performance should be close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the 3-fold cross validation plan from splitPlan\n",
    "k <- 3 # Number of folds\n",
    "mpg$pred.cv <- 0 \n",
    "for(i in 1:3) {\n",
    "  split <- splitPlan[[i]]\n",
    "  model <- lm(cty ~ hwy, data = mpg[split$train,])\n",
    "  mpg$pred.cv[split$app] <- predict(model, newdata = mpg[split$app,])\n",
    "}\n",
    "\n",
    "# Predict from a full model\n",
    "mpg$pred <- predict(lm(cty ~ hwy, data = mpg))\n",
    "\n",
    "# Get the rmse of the full model's predictions\n",
    "rmse(mpg$pred, mpg$cty)\n",
    "# [1] 1.247045\n",
    "\n",
    "# Get the rmse of the cross-validation predictions\n",
    "rmse(mpg$pred.cv, mpg$cty)\n",
    "# [1] 1.260323"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:CHIAPETR]",
   "language": "R",
   "name": "conda-env-CHIAPETR-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
