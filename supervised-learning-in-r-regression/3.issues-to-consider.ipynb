{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the structure of categorical inputs\n",
    "For this exercise you will call ```model.matrix()``` to examine how R represents data with both categorical and numerical inputs for modeling. The dataset flowers (derived from the Sleuth3 package) is loaded into your workspace. It has the following columns:\n",
    "\n",
    "Flowers: the average number of flowers on a meadowfoam plant\n",
    "Intensity: the intensity of a light treatment applied to the plant\n",
    "Time: A categorical variable - when (Late or Early) in the lifecycle the light treatment occurred\n",
    "The ultimate goal is to predict Flowers as a function of Time and Intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call str on flowers to see the types of each column\n",
    "str(flowers)\n",
    "# 'data.frame':\t24 obs. of  3 variables:\n",
    "#  $ Flowers  : num  62.3 77.4 55.3 54.2 49.6 61.9 39.4 45.7 31.3 44.9 ...\n",
    "#  $ Time     : chr  \"Late\" \"Late\" \"Late\" \"Late\" ...\n",
    "#  $ Intensity: int  150 150 300 300 450 450 600 600 750 750 ...\n",
    "\n",
    "# Use unique() to see how many possible values Time takes\n",
    "unique(flowers$Time)\n",
    "# [1] \"Late\"  \"Early\"\n",
    "\n",
    "# Build a formula to express Flowers as a function of Intensity and Time: fmla. Print it\n",
    "(fmla <- as.formula(\"Flowers ~ Intensity + Time\"))\n",
    "Flowers ~ Intensity + Time\n",
    "\n",
    "# Use fmla and model.matrix to see how the data is represented for modeling\n",
    "mmat <- model.matrix(fmla, data = flowers)\n",
    "\n",
    "# Examine the first 20 lines of flowers\n",
    "head(flowers, 20)\n",
    "#    Flowers  Time Intensity\n",
    "# 1     62.3  Late       150\n",
    "# 2     77.4  Late       150\n",
    "# 3     55.3  Late       300\n",
    "# 4     54.2  Late       300\n",
    "# 5     49.6  Late       450\n",
    "# 6     61.9  Late       450\n",
    "# 7     39.4  Late       600\n",
    "# 8     45.7  Late       600\n",
    "# 9     31.3  Late       750\n",
    "# 10    44.9  Late       750\n",
    "# 11    36.8  Late       900\n",
    "# 12    41.9  Late       900\n",
    "# 13    77.8 Early       150\n",
    "# 14    75.6 Early       150\n",
    "# 15    69.1 Early       300\n",
    "# 16    78.0 Early       300\n",
    "# 17    57.0 Early       450\n",
    "# 18    71.1 Early       450\n",
    "# 19    62.9 Early       600\n",
    "# 20    52.2 Early       600\n",
    "\n",
    "# Examine the first 20 lines of mmat\n",
    "head(mmat, 20)\n",
    "#    (Intercept) Intensity TimeLate\n",
    "# 1            1       150        1\n",
    "# 2            1       150        1\n",
    "# 3            1       300        1\n",
    "# 4            1       300        1\n",
    "# 5            1       450        1\n",
    "# 6            1       450        1\n",
    "# 7            1       600        1\n",
    "# 8            1       600        1\n",
    "# 9            1       750        1\n",
    "# 10           1       750        1\n",
    "# 11           1       900        1\n",
    "# 12           1       900        1\n",
    "# 13           1       150        0\n",
    "# 14           1       150        0\n",
    "# 15           1       300        0\n",
    "# 16           1       300        0\n",
    "# 17           1       450        0\n",
    "# 18           1       450        0\n",
    "# 19           1       600        0\n",
    "# 20           1       600        0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling with categorical inputs\n",
    "For this exercise you will fit a linear model to the flowers data, to predict Flowers as a function of Time and Intensity.\n",
    "\n",
    "The model formula fmla that you created in the previous exercise is still in your workspace, as is the model matrix mmat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model to predict Flowers from Intensity and Time : flower_model\n",
    "flower_model <- lm(fmla, data = flowers)\n",
    "\n",
    "# Use summary to examine flower_model \n",
    "summary(flower_model)\n",
    "\n",
    "# Predict the number of flowers on each plant\n",
    "flowers$predictions <- predict(flower_model, flowers)\n",
    "# Call:\n",
    "# lm(formula = fmla, data = flowers)\n",
    "\n",
    "# Residuals:\n",
    "#    Min     1Q Median     3Q    Max \n",
    "# -9.652 -4.139 -1.558  5.632 12.165 \n",
    "\n",
    "# Coefficients:\n",
    "#               Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)  83.464167   3.273772  25.495  < 2e-16 ***\n",
    "# Intensity    -0.040471   0.005132  -7.886 1.04e-07 ***\n",
    "# TimeLate    -12.158333   2.629557  -4.624 0.000146 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 6.441 on 21 degrees of freedom\n",
    "# Multiple R-squared:  0.7992,\tAdjusted R-squared:   0.78 \n",
    "# F-statistic: 41.78 on 2 and 21 DF,  p-value: 4.786e-08\n",
    "\n",
    "# Plot predictions vs actual flowers (predictions on x-axis)\n",
    "ggplot(flowers, aes(x = predictions, y = Flowers)) + \n",
    "  geom_point() +\n",
    "  geom_abline(color = \"blue\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![categorical_inputs_1](./figures/categorical_inputs_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling an interaction\n",
    "In this exercise you will use interactions to model the effect of gender and gastric activity on alcohol metabolism.\n",
    "\n",
    "The data frame alcohol has columns:\n",
    "\n",
    "- Metabol: the alcohol metabolism rate\n",
    "- Gastric: the rate of gastric alcohol dehydrogenase activity\n",
    "- Sex: the sex of the drinker (Male or Female)\n",
    "\n",
    "In the video, we fit three models to the alcohol data:\n",
    "\n",
    "- one with only additive (main effect) terms : \n",
    "    - ```Metabol ~ Gastric + Sex```\n",
    "- two models, each with interactions between gastric activity and sex \n",
    "\n",
    "We saw that one of the models with interaction terms had a better R-squared than the additive model, suggesting that using interaction terms gives a better fit. In this exercise we will compare the R-squared of one of the interaction models to the main-effects-only model.\n",
    "\n",
    "Recall that the operator : designates the interaction between two variables. The operator * designates the interaction between the two variables, plus the main effects.\n",
    "\n",
    "```\n",
    "x*y = x + y + x:y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alcohol is in the workspace\n",
    "summary(alcohol)\n",
    "#     Subject         Metabol          Gastric          Sex    \n",
    "#  Min.   : 1.00   Min.   : 0.100   Min.   :0.800   Female:18  \n",
    "#  1st Qu.: 8.75   1st Qu.: 0.600   1st Qu.:1.200   Male  :14  \n",
    "#  Median :16.50   Median : 1.700   Median :1.600              \n",
    "#  Mean   :16.50   Mean   : 2.422   Mean   :1.863              \n",
    "#  3rd Qu.:24.25   3rd Qu.: 2.925   3rd Qu.:2.200              \n",
    "#  Max.   :32.00   Max.   :12.300   Max.   :5.200              \n",
    "#           Alcohol  \n",
    "#  Alcoholic    : 8  \n",
    "#  Non-alcoholic:24\n",
    "\n",
    "# Create the formula with main effects only\n",
    "(fmla_add <- Metabol ~ Gastric + Sex )\n",
    "# Metabol ~ Gastric + Sex\n",
    "\n",
    "# Create the formula with interactions\n",
    "(fmla_interaction <- Metabol ~ Gastric + Gastric : Sex )\n",
    "# Metabol ~ Gastric + Gastric:Sex\n",
    "\n",
    "# Fit the main effects only model\n",
    "model_add <- lm(fmla_add, alcohol)\n",
    "\n",
    "# Fit the interaction model\n",
    "model_interaction <- lm(fmla_interaction, alcohol)\n",
    "\n",
    "# Call summary on both models and compare\n",
    "summary(model_add)\n",
    "# Call:\n",
    "# lm(formula = fmla_add, data = alcohol)\n",
    "\n",
    "# Residuals:\n",
    "#     Min      1Q  Median      3Q     Max \n",
    "# -2.2779 -0.6328 -0.0966  0.5783  4.5703 \n",
    "\n",
    "# Coefficients:\n",
    "#             Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)  -1.9466     0.5198  -3.745 0.000796 ***\n",
    "# Gastric       1.9656     0.2674   7.352 4.24e-08 ***\n",
    "# SexMale       1.6174     0.5114   3.163 0.003649 ** \n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 1.331 on 29 degrees of freedom\n",
    "# Multiple R-squared:  0.7654,\tAdjusted R-squared:  0.7492 \n",
    "# F-statistic: 47.31 on 2 and 29 DF,  p-value: 7.41e-10\n",
    "\n",
    "summary(model_interaction)\n",
    "# Call:\n",
    "# lm(formula = fmla_interaction, data = alcohol)\n",
    "\n",
    "# Residuals:\n",
    "#     Min      1Q  Median      3Q     Max \n",
    "# -2.4656 -0.5091  0.0143  0.5660  4.0668 \n",
    "\n",
    "# Coefficients:\n",
    "#                 Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)      -0.7504     0.5310  -1.413 0.168236    \n",
    "# Gastric           1.1489     0.3450   3.331 0.002372 ** \n",
    "# Gastric:SexMale   1.0422     0.2412   4.321 0.000166 ***\n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 1.204 on 29 degrees of freedom\n",
    "# Multiple R-squared:  0.8081,\tAdjusted R-squared:  0.7948 \n",
    "# F-statistic: 61.05 on 2 and 29 DF,  p-value: 4.033e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling an interaction (2)\n",
    "In this exercise, you will compare the performance of the interaction model you fit in the previous exercise to the performance of a main-effects only model. Because this data set is small, we will use cross-validation to simulate making predictions on out-of-sample data.\n",
    "\n",
    "You will begin to use the dplyr package to do calculations.\n",
    "\n",
    "- mutate() adds new columns to a tbl (a type of data frame)\n",
    "- group_by() specifies how rows are grouped in a tbl\n",
    "- summarize() computes summary statistics of a column\n",
    "\n",
    "You will also use tidyr's gather() which takes multiple columns and collapses them into key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the splitting plan for 3-fold cross validation\n",
    "set.seed(34245)  # set the seed for reproducibility\n",
    "splitPlan <- kWayCrossValidation(nrow(alcohol), 3, NULL, NULL)\n",
    "\n",
    "# Sample code: Get cross-val predictions for main-effects only model\n",
    "alcohol$pred_add <- 0  # initialize the prediction vector\n",
    "for(i in 1:3) {\n",
    "  split <- splitPlan[[i]]\n",
    "  model_add <- lm(fmla_add, data = alcohol[split$train, ])\n",
    "  alcohol$pred_add[split$app] <- predict(model_add, newdata = alcohol[split$app, ])\n",
    "}\n",
    "\n",
    "# Get the cross-val predictions for the model with interactions\n",
    "alcohol$pred_interaction <- 0 # initialize the prediction vector\n",
    "for(i in 1:3) {\n",
    "  split <- splitPlan[[i]]\n",
    "  model_interaction <- lm(fmla_interaction, data = alcohol[split$train, ])\n",
    "  alcohol$pred_interaction[split$app] <- predict(model_interaction, newdata = alcohol[split$app, ])\n",
    "}\n",
    "\n",
    "# Get RMSE\n",
    "alcohol %>% \n",
    "  gather(key = modeltype, value = pred, pred_add, pred_interaction) %>%\n",
    "  mutate(residuals = Metabol - pred) %>%      \n",
    "  group_by(modeltype) %>%\n",
    "  summarize(rmse = sqrt(mean(residuals^2)))\n",
    "# # A tibble: 2 x 2\n",
    "#   modeltype         rmse\n",
    "#   <chr>            <dbl>\n",
    "# 1 pred_add          1.64\n",
    "# 2 pred_interaction  1.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative error\n",
    "In this exercise, you will compare relative error to absolute error. For the purposes of modeling, we will define relative error as\n",
    "\n",
    "```\n",
    "rel=(y−pred)/y\n",
    "```\n",
    "that is, the error is relative to the true outcome. You will measure the overall relative error of a model using root mean squared relative error:\n",
    "\n",
    "```\n",
    "rmse_rel=sqrt(mean(rel^2))\n",
    "```\n",
    "\n",
    "The example (toy) dataset fdata is loaded in your workspace. It includes the columns:\n",
    "\n",
    "- y: the true output to be predicted by some model; imagine it is the amount of money a customer will spend on a visit to your store.\n",
    "- pred: the predictions of a model that predicts y.\n",
    "- label: categorical: whether y comes from a population that makes small purchases, or large ones.\n",
    "\n",
    "You want to know which model does \"better\": the one predicting the small purchases, or the one predicting large ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdata is in the workspace\n",
    "summary(fdata)\n",
    "#        y                 pred                      label   \n",
    "#  Min.   :  -5.894   Min.   :   1.072   small purchases:50  \n",
    "#  1st Qu.:   5.407   1st Qu.:   6.373   large purchases:50  \n",
    "#  Median :  57.374   Median :  55.693                       \n",
    "#  Mean   : 306.204   Mean   : 305.905                       \n",
    "#  3rd Qu.: 550.903   3rd Qu.: 547.886                       \n",
    "#  Max.   :1101.619   Max.   :1098.896\n",
    "\n",
    "# Examine the data: generate the summaries for the groups large and small:\n",
    "fdata %>% \n",
    "    group_by(label) %>%     # group by small/large purchases\n",
    "    summarize(min  = min(y),   # min of y\n",
    "              mean = mean(y),   # mean of y\n",
    "              max  = max(y))   # max of y\n",
    "# # A tibble: 2 x 4\n",
    "#   label             min   mean    max\n",
    "#   <fct>           <dbl>  <dbl>  <dbl>\n",
    "# 1 small purchases -5.89   6.48   18.6\n",
    "# 2 large purchases 96.1  606.   1102.\n",
    "\n",
    "# Fill in the blanks to add error columns\n",
    "fdata2 <- fdata %>% \n",
    "         group_by(label) %>%       # group by label\n",
    "           mutate(residual = y - pred,  # Residual\n",
    "                  relerr   = (y - pred)/y)  # Relative error\n",
    "\n",
    "# Compare the rmse and rmse.rel of the large and small groups:\n",
    "fdata2 %>% \n",
    "  group_by(label) %>% \n",
    "  summarize(rmse     = sqrt(mean(residual^2)),   # RMSE\n",
    "            rmse.rel = sqrt(mean(relerr^2))) # Root mean squared relative error\n",
    "# # A tibble: 2 x 3\n",
    "#   label            rmse rmse.rel\n",
    "#   <fct>           <dbl>    <dbl>\n",
    "# 1 small purchases  4.01   1.25  \n",
    "# 2 large purchases  5.54   0.0147\n",
    "\n",
    "# Plot the predictions for both groups of purchases\n",
    "ggplot(fdata2, aes(x = pred, y = y, color = label)) + \n",
    "  geom_point() + \n",
    "  geom_abline() + \n",
    "  facet_wrap(~ label, ncol = 1, scales = \"free\") + \n",
    "  ggtitle(\"Outcome vs prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![relative_error_1](./figures/relative_error_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling log-transformed monetary output\n",
    "In this exercise, you will practice modeling on log-transformed monetary output, and then transforming the \"log-money\" predictions back into monetary units. The data loaded into your workspace records subjects' incomes in 2005 (Income2005), as well as the results of several aptitude tests taken by the subjects in 1981:\n",
    "\n",
    "Arith\n",
    "Word\n",
    "Parag\n",
    "Math\n",
    "AFQT (Percentile on the Armed Forces Qualifying Test)\n",
    "The data have already been split into training and test sets (income_train and income_test respectively) and are in the workspace. You will build a model of log(income) from the inputs, and then convert log(income) back into income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine Income2005 in the training set\n",
    "summary(income_train$Income2005)\n",
    "#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
    "#      63   23000   39000   49894   61500  703637\n",
    "\n",
    "# Write the formula for log income as a function of the tests and print it\n",
    "(fmla.log <- log(Income2005) ~ Arith + Word + Parag + Math + AFQT)\n",
    "# log(Income2005) ~ Arith + Word + Parag + Math + AFQT\n",
    "\n",
    "# Fit the linear model\n",
    "model.log <-  lm(fmla.log, data = income_train)\n",
    "\n",
    "# Make predictions on income_test\n",
    "income_test$logpred <- predict(model.log, income_test)\n",
    "summary(income_test$logpred)\n",
    "#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
    "#   9.766  10.133  10.423  10.419  10.705  11.006\n",
    "\n",
    "# Convert the predictions to monetary units\n",
    "income_test$pred.income <- exp(income_test$logpred)\n",
    "summary(income_test$pred.income)\n",
    "#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
    "#   17432   25167   33615   35363   44566   60217\n",
    "\n",
    "#  Plot predicted income (x axis) vs income\n",
    "ggplot(income_test, aes(x = pred.income, y = Income2005)) + \n",
    "  geom_point() + \n",
    "  geom_abline(color = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![modeling_log_transformed_monetary](./figures/modeling_log_transformed_monetary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing RMSE and root-mean-squared Relative Error\n",
    "In this exercise, you will show that log-transforming a monetary output before modeling improves mean relative error (but increases RMSE) compared to modeling the monetary output directly. You will compare the results of model.log from the previous exercise to a model (model.abs) that directly fits income.\n",
    "\n",
    "The income_train and income_test datasets are loaded in your workspace, along with your model, model.log.\n",
    "\n",
    "Also in the workspace:\n",
    "\n",
    "model.abs: a model that directly fits income to the inputs using the formula\n",
    "\n",
    "```\n",
    "Income2005 ~ Arith + Word + Parag + Math + AFQT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.abs is in the workspace\n",
    "summary(model.abs)\n",
    "# Call:\n",
    "# lm(formula = fmla.abs, data = income_train)\n",
    "\n",
    "# Residuals:\n",
    "#    Min     1Q Median     3Q    Max \n",
    "# -78728 -24137  -6979  11964 648573 \n",
    "\n",
    "# Coefficients:\n",
    "#             Estimate Std. Error t value Pr(>|t|)    \n",
    "# (Intercept)  17516.7     6420.1   2.728  0.00642 ** \n",
    "# Arith         1552.3      303.4   5.116 3.41e-07 ***\n",
    "# Word          -132.3      265.0  -0.499  0.61754    \n",
    "# Parag        -1155.1      618.3  -1.868  0.06189 .  \n",
    "# Math           725.5      372.0   1.950  0.05127 .  \n",
    "# AFQT           177.8      144.1   1.234  0.21734    \n",
    "# ---\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "\n",
    "# Residual standard error: 45500 on 2063 degrees of freedom\n",
    "# Multiple R-squared:  0.1165,\tAdjusted R-squared:  0.1144 \n",
    "# F-statistic:  54.4 on 5 and 2063 DF,  p-value: < 2.2e-16\n",
    "\n",
    "# Add predictions to the test set\n",
    "income_test <- income_test %>%\n",
    "  mutate(pred.absmodel = predict(model.abs, income_test),# predictions from model.abs\n",
    "         pred.logmodel = exp(predict(model.log, income_test)))# predictions from model.log\n",
    "\n",
    "# Gather the predictions and calculate residuals and relative error\n",
    "income_long <- income_test %>% \n",
    "  gather(key = modeltype, value = pred, pred.absmodel, pred.logmodel) %>%\n",
    "  mutate(residual = pred - Income2005,   # residuals\n",
    "         relerr   = residual / Income2005)   # relative error\n",
    "\n",
    "# Calculate RMSE and relative RMSE and compare\n",
    "income_long %>% \n",
    "  group_by(modeltype) %>%      # group by modeltype\n",
    "  summarize(rmse     = sqrt(mean(residual^2)),    # RMSE\n",
    "            rmse.rel = sqrt(mean(relerr^2)))    # Root mean squared relative error\n",
    "# # A tibble: 2 x 3\n",
    "#   modeltype       rmse rmse.rel\n",
    "#   <chr>          <dbl>    <dbl>\n",
    "# 1 pred.absmodel 37448.     3.18\n",
    "# 2 pred.logmodel 39235.     2.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input transforms: the \"hockey stick\"\n",
    "In this exercise, we will build a model to predict price from a measure of the house's size (surface area). The data set houseprice has the columns:\n",
    "\n",
    "- price : house price in units of $1000\n",
    "- size: surface area\n",
    "\n",
    "A scatterplot of the data shows that the data is quite non-linear: a sort of \"hockey-stick\" where price is fairly flat for smaller houses, but rises steeply as the house gets larger. Quadratics and tritics are often good functional forms to express hockey-stick like relationships. Note that there may not be a \"physical\" reason that price is related to the square of the size; a quadratic is simply a closed form approximation of the observed relationship.\n",
    "\n",
    "You will fit a model to predict price as a function of the squared size, and look at its fit on the training data.\n",
    "\n",
    "Because ^ is also a symbol to express interactions, use the function I() to treat the expression x^2 “as is”: that is, as the square of x rather than the interaction of x with itself.\n",
    "\n",
    "```\n",
    "exampleFormula = y ~ I(x^2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houseprice is in the workspace\n",
    "summary(houseprice)\n",
    "#       size           price      \n",
    "#  Min.   : 44.0   Min.   : 42.0  \n",
    "#  1st Qu.: 73.5   1st Qu.:164.5  \n",
    "#  Median : 91.0   Median :203.5  \n",
    "#  Mean   : 94.3   Mean   :249.2  \n",
    "#  3rd Qu.:118.5   3rd Qu.:287.8  \n",
    "#  Max.   :150.0   Max.   :573.0\n",
    "\n",
    "# Create the formula for price as a function of squared size\n",
    "(fmla_sqr <- price ~ I(size^2))\n",
    "# price ~ I(size^2)\n",
    "\n",
    "# Fit a model of price as a function of squared size (use fmla_sqr)\n",
    "model_sqr <- lm(fmla_sqr, houseprice)\n",
    "\n",
    "# Fit a model of price as a linear function of size\n",
    "model_lin <- lm(price ~ size, houseprice)\n",
    "\n",
    "# Make predictions and compare\n",
    "houseprice %>% \n",
    "    mutate(pred_lin = predict(model_lin),       # predictions from linear model\n",
    "           pred_sqr = predict(model_sqr)) %>%   # predictions from quadratic model \n",
    "    gather(key = modeltype, value = pred, pred_lin, pred_sqr) %>% # gather the predictions\n",
    "    ggplot(aes(x = size)) + \n",
    "       geom_point(aes(y = price)) +                   # actual prices\n",
    "       geom_line(aes(y = pred, color = modeltype)) + # the predictions\n",
    "       scale_color_brewer(palette = \"Dark2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Input_transforms__the__hockey_stick](./figures/Input_transforms__the__hockey_stick.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input transforms: the \"hockey stick\" (2)\n",
    "In the last exercise you saw that a quadratic model seems to fit the houseprice data better than a linear model. In this exercise you will confirm whether the quadratic model would perform better on out-of-sample data. Since this data set is small, you will use cross-validation. The quadratic formula fmla_sqr that you created in the last exercise is in your workspace.\n",
    "\n",
    "For comparison, the sample code will calculate cross-validation predictions from a linear model price ~ size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houseprice is in the workspace\n",
    "summary(houseprice)\n",
    "\n",
    "# fmla_sqr is in the workspace\n",
    "fmla_sqr\n",
    "\n",
    "# Create a splitting plan for 3-fold cross validation\n",
    "set.seed(34245)  # set the seed for reproducibility\n",
    "splitPlan <- kWayCrossValidation(nrow(houseprice), 3, NULL, NULL)\n",
    "\n",
    "# Sample code: get cross-val predictions for price ~ size\n",
    "houseprice$pred_lin <- 0  # initialize the prediction vector\n",
    "for(i in 1:3) {\n",
    "  split <- splitPlan[[i]]\n",
    "  model_lin <- lm(price ~ size, data = houseprice[split$train,])\n",
    "  houseprice$pred_lin[split$app] <- predict(model_lin, newdata = houseprice[split$app,])\n",
    "}\n",
    "\n",
    "# Get cross-val predictions for price as a function of size^2 (use fmla_sqr)\n",
    "houseprice$pred_sqr <- 0 # initialize the prediction vector\n",
    "for(i in 1:3) {\n",
    "  split <- splitPlan[[i]]\n",
    "  model_sqr <- lm(fmla_sqr, data = houseprice[split$train, ])\n",
    "  houseprice$pred_sqr[split$app] <- predict(model_sqr, newdata = houseprice[split$app, ])\n",
    "}\n",
    "\n",
    "# Gather the predictions and calculate the residuals\n",
    "houseprice_long <- houseprice %>%\n",
    "  gather(key = modeltype, value = pred, pred_lin, pred_sqr) %>%\n",
    "  mutate(residuals = pred - price)\n",
    "\n",
    "# Compare the cross-validated RMSE for the two models\n",
    "houseprice_long %>% \n",
    "  group_by(modeltype) %>% # group by modeltype\n",
    "  summarize(rmse = sqrt(mean(residuals^2)))\n",
    "# # A tibble: 2 x 2\n",
    "#   modeltype  rmse\n",
    "#   <chr>     <dbl>\n",
    "# 1 pred_lin   74.3\n",
    "# 2 pred_sqr   63.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:CHIAPETR]",
   "language": "R",
   "name": "conda-env-CHIAPETR-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
